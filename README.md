# Структура курсовой работы

## Тема: "Генератор описания к входному изображению"

## Введение

Поднимается вопрос об актуальности темы, её применение в повседневной жизни.

## Определения, обозначения и сокращения

## Теоретическая часть (архитектура нейросети)

Описание нейросетей CNN, RNN и LSTM, их математической составляющей и принципов работы. Также будут приводиться аргументы, почему был взят тот или иной тип нейросети.

1. Нейронная сеть CNN
    * Принцип работы
    * Область применения
    * Роль в этой конкретной задаче
2. Нейронная сеть RNN
    * Принцип работы
    * Область применения
3. Нейронная сеть LSTM как модификация RNN
    * Принцип работы
    * Область применения
    * Роль в этой конкретной задаче
4. Метрики оценки качества обучения
    * Основные понятия
    * Принцип работы
    * Косинусный коэффициент (Cosine similarity)
    * Область применения косинусного коэффициента
    * Роль в этой конкретной задаче
5. Функции потерь
    * Основные понятия
    * Принцип работы
    * Перекрестная энтропия (Cross Entropy)
    * Область применения перекрестной энтропии
    * Роль в этой конкретной задаче
6. Задачи генераторов описания входных изображений

## Практическая часть

1. Описание инструментов и библиотек программной реализации.
    * Краткое описание используемых библиотек: NumPy, Pandas, PyTorch.
    * Набор характеристик компьютера, на котором происходило обучение модели (в частности, видеокарта, процессор и ОЗУ).
2. Описание набора данных для обучения и теста (был использован датасет Flickr8K).
3. Приведение характеристик обучения:
    * Скорость обучения
    * Количество эпох
    * Размер batch
    * Learning Rate
    * Количество слоев LSTM
    * Размер словаря (из которого модель будет брать
   слова для создания подписей к изображению)
    * Размер эмбеддинга (embedding_size)
    * Количество признаков выходного вектора LSTM
4. Результаты обучения.
    * Значение метрики косинусного коэффициента (Cosine similarity) на обучающей и тестовой выборках
    * График функции потерь при обучении (значение функции при каждой эпохе)
    * Пример подписи к некоторому входному изображению

## Заключение

Выводы исходя из результатов программной реализации и характеристик обучения, примеры работы обученной модели.

## Листинг программы

<!-- ## Изображение архитектуры ансамбля

![Архитектура ансамбля моделей](pic/arch.png) -->

## Список источников

https://towardsdatascience.com/image-captions-with-deep-learning-state-of-the-art-architectures-3290573712db

https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202

https://keras.io/examples/vision/image_captioning/

https://daniel.lasiman.com/post/image-captioning/

https://arxiv.org/pdf/1607.08822.pdf

https://www.freecodecamp.org/news/building-an-image-caption-generator-with-deep-learning-in-tensorflow-a142722e9b1f/

https://www.ripublication.com/ijaer18/ijaerv13n9_102.pdf
